require("dotenv").config();
// const { OpenAI } = require("openai"); // OpenAI SDK ì£¼ì„ ì²˜ë¦¬
const Anthropic = require("@anthropic-ai/sdk"); // Anthropic SDK ê°€ì ¸ì˜¤ê¸°
const config = require("../config"); // ì„¤ì • íŒŒì¼ ë¡œë“œ
const { redisClient } = require("../utils/redisClient");
const {
  getCurrentInputTokensKey,
  getCurrentOutputTokensKey,
  getRequestTokenKey,
} = require("../utils/redisKeys");
const logger = require("../utils/logger");

// const openai = new OpenAI({ // OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì£¼ì„ ì²˜ë¦¬
//   apiKey: process.env.OPENAI_API_KEY,
// });
const anthropic = new Anthropic({
  // Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
  apiKey: process.env.ANTHROPIC_API_KEY, // .env íŒŒì¼ì—ì„œ API í‚¤ë¥¼ ì½ì–´ì˜´
});

const { apiRateLimits } = config;

/**
 * ğŸ¯ ì„œë²„ ì‹œì‘ ì‹œ ë§Œë£Œëœ í† í° ì˜ˆì•½ë“¤ ì •ë¦¬
 */
async function cleanupOrphanedTokens() {
  try {
    logger.info(
      "[nlpService] Starting cleanup of orphaned token reservations..."
    );

    // ëª¨ë“  ìš”ì²­í‚¤ ì¡°íšŒ (TTL ì—†ìœ¼ë¯€ë¡œ ëª¨ë“  í‚¤ê°€ ë‚¨ì•„ìˆìŒ)
    const keys = await redisClient.keys("anthropic:request:*");
    let totalInputToRemove = 0;
    let totalOutputToRemove = 0;
    let cleanedCount = 0;

    for (const key of keys) {
      try {
        const dataStr = await redisClient.get(key);
        if (!dataStr) continue;

        const data = JSON.parse(dataStr);
        const ageInMs = Date.now() - data.timestamp;

        // ğŸ¯ 70ì´ˆ(70000ms) ë„˜ì€ ìš”ì²­í‚¤ë“¤ ì •ë¦¬ (TTL ì—­í•  ëŒ€ì‹ )
        if (ageInMs > 70000) {
          totalInputToRemove += data.inputTokens || 0;
          totalOutputToRemove += data.outputTokens || 0;
          await redisClient.del(key);
          cleanedCount++;

          logger.debug(
            `[nlpService] Cleaned expired reservation: ${key} (age: ${Math.round(
              ageInMs / 1000
            )}s)`
          );
        }
      } catch (parseError) {
        logger.warn(
          `[nlpService] Failed to parse request key ${key}, deleting:`,
          parseError.message
        );
        await redisClient.del(key);
        cleanedCount++;
      }
    }

    // ëˆ„ì ëœ í† í°ë“¤ í•œë²ˆì— ì œê±°
    if (totalInputToRemove > 0 || totalOutputToRemove > 0) {
      const pipeline = redisClient.multi();
      pipeline.decrBy(getCurrentInputTokensKey(), totalInputToRemove);
      pipeline.decrBy(getCurrentOutputTokensKey(), totalOutputToRemove);
      await pipeline.exec();

      logger.info(
        `[nlpService] Cleanup completed: ${cleanedCount} reservations cleaned, Input: -${totalInputToRemove}, Output: -${totalOutputToRemove}`
      );
    } else {
      logger.info(
        `[nlpService] Cleanup completed: No orphaned reservations found`
      );
    }

    // ì •ë¦¬ í›„ í˜„ì¬ ìƒíƒœ ì¶œë ¥
    const currentInput =
      (await redisClient.get(getCurrentInputTokensKey())) || "0";
    const currentOutput =
      (await redisClient.get(getCurrentOutputTokensKey())) || "0";
    logger.info(
      `[nlpService] Current token state after cleanup - Input: ${currentInput}/${apiRateLimits.MAX_INPUT_TOKENS_PER_MINUTE}, Output: ${currentOutput}/${apiRateLimits.MAX_OUTPUT_TOKENS_PER_MINUTE}`
    );
  } catch (error) {
    logger.error("[nlpService] Token cleanup failed:", error);
  }
}

/**
 * ğŸ¯ ìƒˆë¡œìš´ Sliding Window ë°©ì‹ Rate Limit ì²´í¬
 * @param {string} requestId - ê³ ìœ  ìš”ì²­ ID
 * @returns {Promise<{allowed: boolean, waitTime?: number}>}
 */
async function checkAndReserveTokens(requestId) {
  try {
    const inputTokensKey = getCurrentInputTokensKey();
    const outputTokensKey = getCurrentOutputTokensKey();

    // í˜„ì¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
    const [currentInputStr, currentOutputStr] = await Promise.all([
      redisClient.get(inputTokensKey),
      redisClient.get(outputTokensKey),
    ]);

    const currentInput = parseInt(currentInputStr || "0");
    const currentOutput = parseInt(currentOutputStr || "0");

    const estimatedInput = apiRateLimits.ESTIMATED_INPUT_TOKENS;
    const estimatedOutput = apiRateLimits.ESTIMATED_OUTPUT_TOKENS;

    // í•œë„ ì²´í¬
    if (
      currentInput + estimatedInput >
        apiRateLimits.MAX_INPUT_TOKENS_PER_MINUTE ||
      currentOutput + estimatedOutput >
        apiRateLimits.MAX_OUTPUT_TOKENS_PER_MINUTE
    ) {
      logger.warn(
        `[nlpService] Rate limit reached. Input: ${
          currentInput + estimatedInput
        }/${apiRateLimits.MAX_INPUT_TOKENS_PER_MINUTE}, Output: ${
          currentOutput + estimatedOutput
        }/${apiRateLimits.MAX_OUTPUT_TOKENS_PER_MINUTE}`
      );

      // ë‹¤ìŒ í† í° ì œê±°ê¹Œì§€ ëŒ€ê¸° ì‹œê°„ ì¶”ì • (ê°„ë‹¨íˆ 30ì´ˆë¡œ ì„¤ì •)
      return { allowed: false, waitTime: 30000 };
    }

    // ğŸ¯ í† í° ì˜ˆì•½ (ì›ìì  ì—°ì‚°)
    const pipeline = redisClient.multi();
    pipeline.incrBy(inputTokensKey, estimatedInput);
    pipeline.incrBy(outputTokensKey, estimatedOutput);

    // ğŸ¯ ìš”ì²­ ì •ë³´ ì €ì¥ (TTL ì œê±° - ë¬´ì œí•œ ë³´ì¡´)
    const requestTokenInfo = {
      inputTokens: estimatedInput,
      outputTokens: estimatedOutput,
      timestamp: Date.now(),
    };
    pipeline.set(
      getRequestTokenKey(requestId),
      JSON.stringify(requestTokenInfo)
      // ğŸš« { EX: 70 } TTL ì œê±°!
    );

    await pipeline.exec();

    // ğŸ¯ 1ë¶„ í›„ í† í° ì œê±° ìŠ¤ì¼€ì¤„ë§
    scheduleTokenRemoval(requestId, estimatedInput, estimatedOutput);

    logger.info(
      `[nlpService] Tokens reserved for request ${requestId}. Input: +${estimatedInput}, Output: +${estimatedOutput}`
    );

    return { allowed: true };
  } catch (error) {
    logger.error("[nlpService] Rate limit check failed:", error);
    return { allowed: true }; // ì—ëŸ¬ ì‹œ í—ˆìš© (fallback)
  }
}

/**
 * ğŸ¯ 1ë¶„ í›„ í† í° ì œê±° ìŠ¤ì¼€ì¤„ë§
 * @param {string} requestId
 * @param {number} inputTokens
 * @param {number} outputTokens
 */
function scheduleTokenRemoval(requestId, inputTokens, outputTokens) {
  setTimeout(async () => {
    try {
      await removeTokens(requestId, inputTokens, outputTokens);
    } catch (error) {
      logger.error(
        `[nlpService] Failed to remove tokens for request ${requestId}:`,
        error
      );
    }
  }, 60000); // 60ì´ˆ í›„
}

/**
 * ğŸ¯ í† í° ì œê±° ë° í íŠ¸ë¦¬ê±°
 * @param {string} requestId
 * @param {number} inputTokens
 * @param {number} outputTokens
 */
async function removeTokens(requestId, inputTokens, outputTokens) {
  try {
    const inputTokensKey = getCurrentInputTokensKey();
    const outputTokensKey = getCurrentOutputTokensKey();

    // í† í° ì œê±°
    const pipeline = redisClient.multi();
    pipeline.decrBy(inputTokensKey, inputTokens);
    pipeline.decrBy(outputTokensKey, outputTokens);
    pipeline.del(getRequestTokenKey(requestId));
    await pipeline.exec();

    logger.info(
      `[nlpService] Tokens removed for request ${requestId}. Input: -${inputTokens}, Output: -${outputTokens}`
    );

    // ğŸ¯ EventEmitterë¡œ í íŠ¸ë¦¬ê±°
    try {
      const {
        tokenEventEmitter,
      } = require("../handlers/chatbotWebSocketHandler");
      tokenEventEmitter.emit("tokenRemoved", { requestId });
    } catch (requireError) {
      logger.warn(
        "[nlpService] Could not trigger queue processing:",
        requireError.message
      );
    }
  } catch (error) {
    logger.error(`[nlpService] Error removing tokens:`, error);
  }
}

const getNLPResponse = async function* (systemPrompt, userMessages, requestId) {
  // ğŸ¯ í† í° ì˜ˆì•½ ì²´í¬
  const rateLimitCheck = await checkAndReserveTokens(requestId);
  if (!rateLimitCheck.allowed) {
    throw new Error(`RATE_LIMIT_EXCEEDED:${rateLimitCheck.waitTime}`);
  }

  try {
    const stream = await anthropic.messages.stream({
      model: config.anthropicAI.MODEL,
      system: systemPrompt,
      messages: userMessages,
      max_tokens: config.anthropicAI.MAX_TOKENS,
      temperature: config.anthropicAI.TEMPERATURE,
    });

    for await (const event of stream) {
      if (
        event.type === "content_block_delta" &&
        event.delta?.type === "text_delta"
      ) {
        yield event.delta.text;
      }
    }
  } catch (error) {
    logger.error("[nlpService] Error in getNLPResponse (Anthropic):", error);

    // Anthropic íŠ¹ì • ì—ëŸ¬ ë¶„ë¥˜
    if (error instanceof Anthropic.APIError) {
      if (error.error?.type === "overloaded_error") {
        throw new Error(`ANTHROPIC_OVERLOADED:${error.message}`);
      } else if (error.error?.type === "rate_limit_error") {
        throw new Error(`ANTHROPIC_RATE_LIMIT:${error.message}`);
      }
    }

    throw error;
  }
};

module.exports = {
  getNLPResponse,
  cleanupOrphanedTokens, // ğŸ¯ ìƒˆë¡œ export
};
